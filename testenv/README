This document describes the working of the GNU Wget Test Suite.

Install Instructions:
=====================================================================

This Test Suite exploits the Parallel Test Harness available in
GNU Autotools. Since it uses features from a relatively recent verion
of Autotools, the minimum required version as been bumped up to 1.12.
Even with Automake v1.12, one MUST run automake with the
--add-missing switch to add the required driver files to the repo.
This is not required as of Automake v1.13.
Run the './configure' command to generate the Makefile and then run
'make check' to execute the Test Suite.

File List:
=====================================================================

    * HTTPServer.py: This file contains a custom, programmatically
    configurable HTTP Server for testing Wget. It runs an instance
    of Python's http.server module.

    * TestEnv.py: This file contains various functions and global
    variables for each instance of the server that is initiated.
    It includes functions to start and stop the server, to initialze
    the test environment and to cleanup after a test.

    * runTest.py: This file is the single entry and exit point for
    all tests. Every test must be invoked through this script. This
    script will parse the Test Case file, spawn the server, execute
    the tests and analyse the results.

    * TestProto: This is a prototype Test Case file. This is a valid
    XML file. The file defines all the acceptable elements and their
    uses. Typically, one must copy this file and edit it for writing
    Test Cases.

    * ColourTerm.py: A custom library for printing coloured output to
    the terminal. Currently it only supports 4 colours in a *nix
    environment.

Working:
=====================================================================

A singular Test must be invoked in the following manner:
$ ./runTest.py <Name(s) of Test File(s)>
The script will then parse the respective files for various input
elements. A directory with the name <Test name>-test will be created
and the PWD will be changed to this directory. The server is then
spawned with the required configuration elements. A blocking call to
Wget is made with the command line arguments specified in the Test
Case along with the list of URLs that it must download. The server is
killed once Wget returns and the following checks are used to
determine the pass/fail status of the test:
    * Return Code: The Exit code of Wget is matched against the
    expected Exit Code as mentioned in the Test Case File.
    * Downloaded Files: Check whether the expected downloaded files
    exist on disk.
    * File Content: Test whether the file contents were correctly
    downloaded by Wget and not corrupted mid-way.
    * Excess Files: Check to see whether any unexpected files were
    downloaded by Wget.

Exit Codes:
=====================================================================

Following is a list of Exit Status Codes for the runTest Module:
*   0  Test Successful
*  77  Test Skipped
*  99  Hard Error
* 100  Test Failed

Tests are skipped when they are either not supported by the platform,
or Wget is compiled with support for that feature.

Hard Errors occur when either the Test File could not be found or
parsed successfully.

Other errors in the code are currently not caught and may cause
unhandled exceptions.

Environment Variables:
=====================================================================

* NO_CLEANUP: Do not remove the temporary files created by the test.
  This will prevent the ${testname}-test directory from being deleted

Writing New Tests:
=====================================================================

The test case files are pure and valid XML files. This test suite is
written with the objective of making it easy to write new tests.
A Test Case file begins with WgetTest as the Root Element and all the
other details are provided within the WgetTest Elements.

See TestProto for an example of how to write Test Case files. The
recommended method for writign new Test Case files is to copy
TestProto and modify it to ones needs.

See README.testfile for a list and detailed explanation of the
various elements supported by this Test Suite.

In case you require any functionality that is not currently defined
in README.testfile, you should add the required code in TestEnv.py.
In a majority of cases, you want to add a new Special Command.
In which case, you should edit the parse_special () function to
parse the new command and add the required code there.
In other cases, please ensure that Tests that do not need this
feature skip the whole block. This is required since we have a
single driver script which will call ALL the methods. It is the
responsibility of the method to handle these cases.

Once a new Test File is created, it must be added to the TESTS
variable in Makefile.am. This way the Test will be executed on
running a 'make check'.
If a Test is expected to fail on the current master branch, then the
Test should also be added to the XFAIL_TESTS variable. This will
allow expected failures to pass through. If a test mentioned in the
XFAIL_TESTS variable passes, it gets red-flagged as a XPASS.

Requirements:
=====================================================================

1. Python   >= 3.2
2. Automake >= 1.12
